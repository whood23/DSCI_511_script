{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for webscraping KProfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def load_kaggle_csv_data(filepath):\n",
    "    \"\"\"\n",
    "    Opens & loads Kaggle Kpop CSV file contents as a list (each row = list)\n",
    "        Note: Header = kpop_csv_data[0] \n",
    "    \"\"\"   \n",
    "    reader = csv.reader(open(filepath,\"r\"))\n",
    "    kpop_csv_data = list(reader)\n",
    "    return kpop_csv_data\n",
    "\n",
    "def get_kpop_artist_list(kpop_csv_data):\n",
    "    \"\"\"\n",
    "    Takes in kpop_metadata (from CSV file) & generates a set of kpop artists for the other fucntions.\n",
    "        Turns the list into a set to remove duplicates & converts back to a list. Returns a list to \n",
    "        avoid breaking other functions in case they do not work with sets.\n",
    "    \"\"\"\n",
    "    messy_kpop_artist_list = []\n",
    "    for artist in kpop_csv_data[1:]:\n",
    "        messy_kpop_artist_list.append(artist[0])\n",
    "    no_duplicate_artsits = set(messy_kpop_artist_list)\n",
    "    kpop_artist_list_from_csv = list(no_duplicate_artsits) \n",
    "    return kpop_artist_list_from_csv\n",
    "\n",
    "def slugify_kpop_artist_list(kpop_artist_list_from_csv):\n",
    "    \"\"\"\n",
    "    Formats artist names for use in URLs. Replaces space characters with hyphens.\n",
    "        Without doing this, we wouldn't be able to scrape the Stray Kids webpage.\n",
    "        For KProfile site, the URLs are not case sensitive so we do not apply case formatting.\n",
    "    \"\"\"\n",
    "    kpop_artist_list = []\n",
    "    for artist in kpop_artist_list_from_csv:\n",
    "        kpop_artist_list.append(artist.replace(\" \", \"-\"))  \n",
    "    return kpop_artist_list      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def get_album_content(kpop_artist):\n",
    "    '''\n",
    "    Returns beautiful soup content for a kpop artist's discography ('disc' for short).\n",
    "        Soup content criteria: div with the class 'entry-content herald-entry-content'.\n",
    "        Criteria is true for all group discography pages.\n",
    "    '''\n",
    "    disc_page = (f\"https://kprofiles.com/{kpop_artist}-discography/\")\n",
    "    disc_soup = BeautifulSoup(requests.get(disc_page).text, 'html.parser')\n",
    "    disc_soup = disc_soup.find(\"div\", {'class': \"entry-content herald-entry-content\"})\n",
    "    return disc_soup\n",
    "\n",
    "def get_album_title_content(disc_soup):\n",
    "    \"\"\"\n",
    "    Gets album titles for all groups -- applies filterting for special cases.\n",
    "        Some of Treasure's, (G)I-dle's, and ITZY's albums are randomly formatted in separate p tags, unlike most group pages.\n",
    "        This function grabs all albums & filters out irrelevant info. \n",
    "    \"\"\"\n",
    "    ptags = [tag for tag in disc_soup.find_all(\"p\")]\n",
    "    album_titles = []\n",
    "    # pattern filters out lines that start with \"Release date\" and track numbers (1., 2., etc.)\n",
    "    pattern = r'(^[^Release|\\d]+)'\n",
    "    for tag in ptags:\n",
    "        lines = tag.text.split(\"\\n\")\n",
    "        if 2 >= len(lines):\n",
    "            for words in lines:\n",
    "                if (\n",
    "                    (re.match(pattern, words)) and (\n",
    "                        (\n",
    "                            \"album\" not in words.lower())\n",
    "                            and (\"discography\" not in words.lower()) \n",
    "                            and (\"ost\" not in words.lower()) \n",
    "                            and (\"single\" not in words.lower())\n",
    "                            and (\"click the songs in blue\" not in words.lower())\n",
    "                            and (\"songhaena\" not in words.lower())\n",
    "                            and (\"comment\" not in words.lower())\n",
    "                            and (\"alouette\" not in words.lower())\n",
    "                            and (\"special thanks\" not in words.lower())\n",
    "                            and (\"made by\" not in words.lower())\n",
    "                            and (\"are marked in bold\" not in words.lower())\n",
    "                            and (\"credits\" not in words.lower())\n",
    "                            and (\"journey through iz*one history\" not in words.lower())\n",
    "                        )\n",
    "                    ):\n",
    "                    album_titles.append(unicodedata.normalize('NFKD', words))\n",
    "        else:\n",
    "            title = tag.text.split(\"\\n\")[0]\n",
    "            if \"release date\" in lines[1].lower():\n",
    "                album_titles.append(unicodedata.normalize('NFKD', title))\n",
    "    return album_titles\n",
    "\n",
    "def get_album_titles(kpop_artist):\n",
    "    \"\"\"\n",
    "    Takes in artist name & returns a list of album titles for the artist.\n",
    "    \"\"\"\n",
    "    soup = get_album_content(kpop_artist)\n",
    "    album_titles = get_album_title_content(soup)\n",
    "    return album_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "from datetime import datetime\n",
    "\n",
    "def get_release_dates_content(disc_soup):\n",
    "    \"\"\"\n",
    "    Returns a list of album release dates (as strings) from group discography page.\n",
    "        Release date criteria: the phrase 'release date' is in lines.\n",
    "        Returned list is semi clean, with \"Release Date: \" removed & nonbreaking spaces formatted\n",
    "        Some lists use \"3rd\" or \"2nd\" for dates, so further cleaning is needed.\n",
    "    \"\"\"\n",
    "    ptags = [tag for tag in disc_soup.find_all(\"p\")]\n",
    "    album_release_dates = []\n",
    "    pattern = r\"(^[Rrelas Ddt:]{14})\"\n",
    "    for tag in ptags:\n",
    "        lines = tag.text.split(\"\\n\")\n",
    "        if 2 >= len(lines):\n",
    "            for words in lines:\n",
    "                if 'release date' in words.lower():\n",
    "                    album_release_dates.append(re.sub(pattern, '', (unicodedata.normalize('NFKD', words))))\n",
    "        else:\n",
    "            release_date = tag.text.split(\"\\n\")[1]            \n",
    "            if \"release date\" in lines[1].lower():\n",
    "                    album_release_dates.append(re.sub(pattern, '', (unicodedata.normalize('NFKD', release_date))))     \n",
    "    return album_release_dates\n",
    "\n",
    "def get_loona_release_dates_content(disc_soup):\n",
    "    # reduces all dates to single release dates (Loona has two release dates for two different albums) \n",
    "    date_pattern = r\"(\\w+ \\d{1,2}, \\d{4})\"\n",
    "    album_release_dates = get_release_dates_content(disc_soup)\n",
    "    result =  list(map(lambda date: re.search(date_pattern, date).group(0),\n",
    "                       album_release_dates))\n",
    "    return result\n",
    "\n",
    "def clean_release_dates(album_release_dates):\n",
    "    \"\"\"\n",
    "    Returns a list of album release dates (as strings) from group discography page that are fully cleaned.\n",
    "        Specifically: this replaces the non-digit characters in \"2nd\",\"1st\",\"3rd\",\"24th\" with an empty string \n",
    "        (using clean_date_pattern & regex substitution).\n",
    "    \"\"\"\n",
    "    clean_date_pattern = r\"(?<=\\d)(st|nd|rd|th)\\b\"\n",
    "    cleaned_album_dates = [re.sub(clean_date_pattern, '', date) for date in album_release_dates]\n",
    "    return cleaned_album_dates\n",
    "\n",
    "def format_release_dates(cleaned_album_dates):\n",
    "    \"\"\"\n",
    "    Return a list of ablum release dates in the MM/DD/YYYY format ('%m/%d/$Y') instead of 'Month, day, year'.\n",
    "    \"\"\"  \n",
    "    dt_album_dates = [parser.parse(date) for date in cleaned_album_dates]\n",
    "    formatted_album_dates = [date.strftime(\"%m/%d/%Y\") for date in dt_album_dates]\n",
    "    return formatted_album_dates\n",
    "\n",
    "def get_album_release_dates(kpop_artist):\n",
    "    \"\"\"\n",
    "    Given a Kpop group name, this function returns a list of album release dates, formatted as MM/DD/YYYY, for each album.\n",
    "        Output is a list of strings. \n",
    "    \"\"\"\n",
    "    soup = get_album_content(kpop_artist)\n",
    "    if kpop_artist == \"Loona\":\n",
    "        messy_dates = get_loona_release_dates_content(soup)\n",
    "    else:\n",
    "        messy_dates = get_release_dates_content(soup)\n",
    "    unformatted_dates = clean_release_dates(messy_dates)\n",
    "    album_release_dates = format_release_dates(unformatted_dates)\n",
    "    return album_release_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_tracks_if_ordered(disc_soup):\n",
    "    \"\"\"\n",
    "    Returns a list of album tracks for each album. Used for web pages with ordered list formatting and consistent ptags. \n",
    "    \"\"\"\n",
    "    list_of_disc_tracks = [[ptag.text for ptag in tag.find_all(\"li\")] for tag in disc_soup.find_all(\"ol\")]\n",
    "    return list_of_disc_tracks\n",
    "\n",
    "def get_album_tracks_if_verivery(disc_soup):\n",
    "    \"\"\"\n",
    "    Returns a list of album tracks for each Verivery album because this group page also has unique html. The track info is in\n",
    "        the same ptag as the album ttile. Tracks are also manually numbered on this page, so this is removed using regex.    \n",
    "    \"\"\"\n",
    "    album_tracks_list = []\n",
    "    pattern = r'^[0-9]+\\. '\n",
    "    ptags = disc_soup.find_all(\"p\")\n",
    "    for tag in ptags:\n",
    "        album_info = tag.text.split(\"\\n\")\n",
    "        if len(album_info) < 2:\n",
    "            continue        \n",
    "        tracks = album_info[2:]\n",
    "        for track in tracks:\n",
    "            # this group's disc. webpage starts each album list with an empty string\n",
    "            # we use this to start each album's track list\n",
    "            # then we append each track (removing track numbers) to the last album list added\n",
    "            if track == '':\n",
    "                album_tracks_list.append([])\n",
    "            else:\n",
    "                album_tracks_list[-1].append(re.sub(pattern, '', track))\n",
    "    return album_tracks_list\n",
    "\n",
    "def get_album_tracks_if_treasure(disc_soup):\n",
    "    '''\n",
    "    Gets album tracks if artist is 'Treasure'\n",
    "    '''\n",
    "    album_tracks_list = []\n",
    "    ptags = disc_soup.find_all(\"p\")\n",
    "    pattern = r'^[0-9]+\\. '    \n",
    "    for tag in ptags[1:]:\n",
    "        if \"release date\" in tag.text.lower():\n",
    "            album_tracks_list.append([])\n",
    "        else:\n",
    "            if re.match(pattern, tag.text): \n",
    "                if '\\n' in tag.text:\n",
    "                    tracks = tag.text.split('\\n')\n",
    "                    for track in tracks:\n",
    "                        album_tracks_list[-1].append(re.sub(pattern, '', track))\n",
    "                else:\n",
    "                    album_tracks_list[-1].append(re.sub(pattern, '', tag.text))\n",
    "    return album_tracks_list\n",
    "\n",
    "def get_album_tracks_if_ateez(disc_soup):\n",
    "    '''\n",
    "    Gets album tracks if artist is 'Ateez'\n",
    "    '''\n",
    "    album_tracks_list = []\n",
    "    o_tags = disc_soup.find_all('ol')\n",
    "    for o_tag in o_tags:\n",
    "        album_tracks_list.append([])\n",
    "        li_tags = o_tag.find_all('li')\n",
    "        for li in li_tags:\n",
    "            album_tracks_list[-1].append(li.text) \n",
    "    return album_tracks_list\n",
    "\n",
    "def get_album_tracks(kpop_artist):\n",
    "    \"\"\"\n",
    "    Returns a list of album tracks for each kpop artist.\n",
    "    \"\"\"\n",
    "    soup = get_album_content(kpop_artist)\n",
    "    if kpop_artist == 'Treasure':\n",
    "        return get_album_tracks_if_treasure(soup)\n",
    "    elif kpop_artist == 'Verivery':\n",
    "        return get_album_tracks_if_verivery(soup)\n",
    "    elif kpop_artist == 'Ateez':\n",
    "        return get_album_tracks_if_ateez(soup)\n",
    "    else:\n",
    "        return get_album_tracks_if_ordered(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discography(kpop_artist):\n",
    "    \"\"\"\n",
    "    Take artist name to output innner dict. Run for each artist in later func.\n",
    "    \"\"\"\n",
    "    albums = get_album_titles(kpop_artist)\n",
    "    all_album_tracks = get_album_tracks(kpop_artist)\n",
    "    all_release_dates = get_album_release_dates(kpop_artist)\n",
    "    discography = {}\n",
    "   \n",
    "    for album, album_tracks, release_date in zip(albums, all_album_tracks, all_release_dates):\n",
    "        discography[album] = {'release date': release_date, 'album tracks': album_tracks} \n",
    "    \n",
    "    return discography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_artist_dict_from_csv(filepath):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes in Kpop CSV file name & returns dictionary by webscraping artist names from KProfile site\n",
    "        Applies all functions defined earlier\n",
    "    \"\"\"\n",
    "    kpop_csv_data = load_kaggle_csv_data(filepath)\n",
    "    unformatted_list = get_kpop_artist_list(kpop_csv_data)\n",
    "    kpop_artist_list = slugify_kpop_artist_list(unformatted_list)\n",
    "    artist_dict = {}\n",
    "    for artist in kpop_artist_list:\n",
    "        artist_dict[artist] = make_discography(artist)\n",
    "    return artist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run to make JSON file for webscraped artist dictionary\n",
    "\n",
    "kpop_filepath = 'kpop_data.csv'\n",
    "artist_dict = get_artist_dict_from_csv(kpop_filepath)\n",
    "with open('kpop_artist_dictionary.json', 'w', encoding='utf-8') as fp:\n",
    "    json.dump(artist_dict, fp, ensure_ascii=False, sort_keys=True, indent=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7aa93e3a21d08b6ba70af284853c9a001469e12e0e79d919bd867503abf84f0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
